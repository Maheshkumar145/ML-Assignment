{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNp5czyl2Eo9t7N3Gyq4Y1B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maheshkumar145/ML-Assignment/blob/main/ML_Assignment_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is the definition of a target function?**\n",
        "\n",
        "**Ans:** A target function, in machine learning, is a method for solving a problem that an AI algorithm parses its training data to find. Once an algorithm finds its target function, that function can be used to predict results (predictive analysis)."
      ],
      "metadata": {
        "id": "8Fq31yawbSZp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. What are predictive models, and how do they work? What are descriptive types, and how do you use them? Examples of both types of models should be provided. Distinguish between these two forms of models.**\n",
        "\n",
        "**Ans:** Predictive modeling is a commonly used statistical technique to predict future behavior. Predictive modeling solutions are a form of data-mining technology that works by analyzing historical and current data and generating a model to help predict future outcomes.\n",
        "\n",
        "Descriptive Analysis in Machine Learning is all about perspective to understand the data and its different existing patterns. Basically, it is part of four types of Data Analysis concepts."
      ],
      "metadata": {
        "id": "L0XwsDSrbtfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Describe the method of assessing a classification model's efficiency in detail. Describe the various measurement parameters.**\n",
        "\n",
        "**Ans:**\n",
        "* Confusion Matrix\n",
        "* Precision\n",
        "* Recall/ Sensitivity\n",
        "* Specificity\n",
        "* F1-Score\n",
        "* AUC & ROC Curve\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Dx75f00Bbrpf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.**\n",
        "\n",
        "**i. In the sense of machine learning models, what is underfitting? What is the most common reason for underfitting?**\n",
        "\n",
        "**Ans:** Underfitting occurs when our machine learning model is not able to capture the underlying trend of the data.\n",
        "It occurs when a model is too simple, which can be a result of a model needing more training time, more input features, or less regularization. Like overfitting, when a model is underfitted, it cannot establish the dominant trend within the data, resulting in training errors and poor performance of the model.\n",
        "\n",
        "**ii. What does it mean to overfit? When is it going to happen?**\n",
        "\n",
        "**Ans:** Overfitting occurs when the model cannot generalize and fits too closely to the training dataset instead. Overfitting happens due to several reasons, such as\n",
        "\n",
        "* The training data size is too small and does not contain enough data samples to accurately represent all possible input data values.\n",
        "\n",
        "* The training data contains large amounts of irrelevant information, called noisy data.\n",
        "\n",
        "* The model trains for too long on a single sample set of data.\n",
        "\n",
        "* The model complexity is high, so it learns the noise within the training data.\n",
        "\n",
        "**iii. In the sense of model fitting, explain the bias-variance trade-off**\n",
        "\n",
        "**Ans:** In statistics and machine learning, the bias–variance tradeoff is the property of a model that the variance of the parameter estimated across samples can be reduced by increasing the bias in the estimated parameters."
      ],
      "metadata": {
        "id": "7KalDjT2bpVB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Is it possible to boost the efficiency of a learning model? If so, please clarify how.**\n",
        "\n",
        "**Ans:** \n",
        "\n",
        "1.Reframe the problem.\n",
        "\n",
        "2.Provide more data samples\n",
        "\n",
        "3.Add context to the data\n",
        "\n",
        "4.Use meaningful data and features\n",
        "\n",
        "5.Cross-validation\n",
        "\n",
        "6.Hyperparameter tuning\n",
        "\n",
        "7.Choose a different algorithm"
      ],
      "metadata": {
        "id": "1hlMZPxGbmmo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. How would you rate an unsupervised learning model's success? What are the most common success indicators for an unsupervised learning model?**\n",
        "\n",
        "**Ans:** \n",
        "**Clustering performance:** In clustering tasks, the goal is to group similar data points together. Success can be measured by evaluating the quality of the resulting clusters using metrics such as silhouette score, purity, or entropy.\n",
        "\n",
        "**Anomaly detection:** Unsupervised learning can also be used to identify unusual or anomalous data points. Success can be evaluated by measuring the model's ability to correctly identify anomalous instances, often measured in terms of precision, recall, or F1 score.\n",
        "\n",
        "**Dimensionality reduction:** Unsupervised learning can be used to reduce the number of features in a dataset while preserving the most relevant information. Success can be measured by evaluating the quality of the reduced representation using metrics such as explained variance, reconstruction error, or mutual information.\n",
        "\n",
        "**Generative modeling:** Unsupervised learning can also be used to learn a generative model of a dataset, allowing the model to generate new, realistic examples. Success can be evaluated by measuring the quality of the generated examples using metrics such as likelihood, diversity, or visual inspection."
      ],
      "metadata": {
        "id": "m3w2F5fNbkS_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Is it possible to use a classification model for numerical data or a regression model for categorical data with a classification model? Explain your answer.**\n",
        "\n",
        "**Ans:** No, it is not recommended to use a classification model for numerical data or a regression model for categorical data. This is because classification models are specifically designed to predict discrete categories or classes, while regression models are designed to predict continuous numerical values"
      ],
      "metadata": {
        "id": "BcX7o99Xbha4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Describe the predictive modeling method for numerical values. What distinguishes it from categorical predictive modeling?**\n",
        "\n",
        "**Ans:** Predictive modeling for numerical values, also known as regression modeling, is a method used to predict a continuous numerical output variable based on one or more input variables, which can be either numerical or categorical. The goal of regression modeling is to identify the relationship between the input variables and the output variable, and to use this relationship to make accurate predictions on new, unseen data."
      ],
      "metadata": {
        "id": "YqwyapYTbe34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. The following data were collected when using a classification model to predict the malignancy of a group of patients' tumors:**\n",
        "\n",
        "**i. Accurate estimates – 15 cancerous, 75 benign**\n",
        "\n",
        "**ii. Wrong predictions – 3 cancerous, 7 benign**\n",
        "\n",
        "**Determine the model's error rate, Kappa value, sensitivity, precision, and F-measure.**\n",
        "\n",
        "**Ans:**\n",
        "\n",
        "\n",
        "**Error rate** = (FP + FN) / (TP + TN + FP + FN) = (7 + 3) / (15 + 75 + 7 + 3) = 0.1 or 10%\n",
        "\n",
        "**Kappa value:** = (TP + TN - (FP + FN)) / (TP + TN + FP + FN - (TP + TN - FP - FN)) = (15 + 75 - (7 + 3)) / (15 + 75 + 7 + 3 - (15 + 75 - 7 - 3)) = 0.708 or 70.8%\n",
        "\n",
        "**Sensitivity** = TP / (TP + FN) = 15 / (15 + 3) = 0.833 or 83.3%\n",
        "\n",
        "**Precision** = TP / (TP + FP) = 15 / (15 + 7) = 0.682 or 68.2%\n",
        "\n",
        "**F-measure** = 2 * (precision * sensitivity) / (precision + sensitivity) = 2 * (0.682 * 0.833) / (0.682 + 0.833) = 0.750 or 75.0%\n",
        "\n",
        "Therefore, the classification model has an error rate of 10%, a Kappa value of 70.8%, a sensitivity of 83.3%, a precision of 68.2%, and an F-measure of 75.0%."
      ],
      "metadata": {
        "id": "BWfqNQmYbcaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. Make quick notes on:**\n",
        "\n",
        "**1. The process of holding out:**\n",
        "The process of holding out involves reserving a portion of the available dataset as a validation set for testing the performance of a machine learning model. The held-out portion is not used during training and is only used for evaluation purposes. This technique helps to prevent overfitting and provides a more accurate estimate of the model's generalization performance.\n",
        "\n",
        "**2. Cross-validation by tenfold:**\n",
        "Cross-validation by tenfold is a technique for evaluating the performance of a machine learning model by splitting the dataset into ten equal parts, using nine parts for training and one part for testing, and repeating this process ten times, each time using a different part for testing. This technique helps to provide a more accurate estimate of the model's generalization performance and is commonly used when the dataset is small.\n",
        "\n",
        "\n",
        "         \n",
        "**3. Adjusting the parameters:**\n",
        "Adjusting the parameters of a machine learning model involves selecting the optimal values for the model's hyperparameters to improve the model's performance. Hyperparameters are settings that are not learned from the data, but rather are specified by the user or chosen through a search process. Common techniques for adjusting the parameters of a machine learning model include grid search, random search, and Bayesian optimization. The optimal parameter values are typically chosen based on the performance of the model on a held-out validation set or through cross-validation."
      ],
      "metadata": {
        "id": "UnNJyGhkbYwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Define the following terms:**\n",
        "\n",
        "**1. Purity vs. Silhouette width:**\n",
        "Purity is a measure of the homogeneity of clusters in clustering analysis, where a cluster is considered pure if it contains only one class of data points. Purity is calculated as the ratio of the number of data points in the cluster belonging to the most frequent class to the total number of data points in the cluster.\n",
        "\n",
        "Silhouette width is a measure of the similarity between a data point and its own cluster compared to other clusters. It ranges from -1 to 1, where a high value indicates that the data point is well-matched to its own cluster and poorly-matched to neighboring clusters.\n",
        "\n",
        "**2. Boosting vs. Bagging:**\n",
        "Boosting is an ensemble learning technique in which a series of weak models are trained sequentially, each one learning from the mistakes of its predecessors. The final model is a weighted combination of these weak models, where each weak model is assigned a weight based on its performance.\n",
        "\n",
        "Bagging, or bootstrap aggregating, is an ensemble learning technique in which multiple samples of the training data are drawn with replacement, and a separate model is trained on each sample. The final model is an average of the predictions made by these models.\n",
        "\n",
        "**3. The eager learner vs. the lazy learner:**\n",
        "The eager learner, also known as the eager or eager execution approach, is a type of machine learning algorithm that learns a model during the training phase and uses this model to make predictions during the testing phase. Examples of eager learning algorithms include decision trees, artificial neural networks, and logistic regression models.\n",
        "\n",
        "The lazy learner, also known as the lazy or lazy evaluation approach, is a type of machine learning algorithm that does not learn a model during the training phase. Instead, it stores the training data and uses this data to make predictions during the testing phase. Examples of lazy learning algorithms include k-nearest neighbors (KNN) and case-based reasoning (CBR) models."
      ],
      "metadata": {
        "id": "rfvxRkaHbVxw"
      }
    }
  ]
}