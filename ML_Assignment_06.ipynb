{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNaXsxIXxJlKWALFCxqwkK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maheshkumar145/ML-Assignment/blob/main/ML_Assignment_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. In the sense of machine learning, what is a model? What is the best way to train a model?**\n",
        "\n",
        "**Ans:** A machine learning model is a file that has been trained to recognize certain types of patterns. You train a model over a set of data, providing it an algorithm that it can use to reason over and learn from those data.\n",
        "\n",
        "There are 3 ways to train using supervised, Unsupervised and Reinforcement trainings."
      ],
      "metadata": {
        "id": "EIMLGnRekaiN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. In the sense of machine learning, explain the \"No Free Lunch\" theorem?**\n",
        "\n",
        "**Ans:** No Free Lunch Theorem argues that, without having substantive information about the modeling problem, there is no single model that will always do better than any other model. Because of this, a strong case can be made to try a wide variety of techniques, then determine which model to focus on."
      ],
      "metadata": {
        "id": "Kaftit7QkZX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Describe the K-fold cross-validation mechanism in detail?**\n",
        "\n",
        "**Ans:** K-fold Cross-Validation is when the dataset is split into a K number of folds and is used to evaluate the model's ability when given new data. K refers to the number of groups the data sample is split into. For example, if you see that the k-value is 5, we can call this a 5-fold cross-validation."
      ],
      "metadata": {
        "id": "KsTep-vbkX7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Describe the bootstrap sampling method. What is the aim of it?**\n",
        "\n",
        "**Ans:** The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement. It can be used to estimate summary statistics such as the mean or standard deviation."
      ],
      "metadata": {
        "id": "UgJKE5_fkU4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. What is the significance of calculating the Kappa value for a classification model? Demonstrate how to measure the Kappa value of a classification model using a sample collection of results.**\n",
        "\n",
        "**Ans:** The kappa statistic is frequently used to test interrater reliability. The importance of rater reliability lies in the fact that it represents the extent to which the data collected in the study are correct representations of the variables measured.\n",
        " \n",
        "Kappa can range from 0 to 1. A value of 0 means that there is no agreement between treal-world observer vs classification model i.e., rayers, and a value of 1 means that there is perfect agreement between the raters. In most cases, anything over 0.7 is considered to be very good agreement."
      ],
      "metadata": {
        "id": "8gC6QYgLkTJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Describe the model ensemble method. In machine learning, what part does it play?**\n",
        "\n",
        "**Ans:** Ensemble methods are techniques that create multiple models and then combine them to produce improved results. Ensemble methods usually produces more accurate solutions than a single model would. This has been the case in a number of machine learning competitions, where the winning solutions used ensemble methods."
      ],
      "metadata": {
        "id": "Tfgc55XCkQT0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. What is a descriptive model's main purpose?**\n",
        "\n",
        "**Ans:** Descriptive modeling is a mathematical process that describes real-world events and the relationships between factors responsible for them. The process is used by consumer-driven organizations to help them target their marketing and advertising efforts"
      ],
      "metadata": {
        "id": "X290yHpOkOdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Describe how to evaluate a linear regression model?**\n",
        "\n",
        "**Ans:**  \n",
        "There are 3 main metrics for model evaluation in regression:\n",
        "1. R Square/Adjusted R Square.\n",
        "2. Mean Square Error(MSE)/Root Mean Square Error(RMSE)\n",
        "3. Mean Absolute Error(MAE)"
      ],
      "metadata": {
        "id": "W69hVB4nkL81"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Distinguish :**\n",
        "\n",
        "**Descriptive vs. predictive models:** Models that are primarily used for understanding, predicting and communicating are referred to as descriptive models, whereas models mainly used for implementation are called prescriptive models. This contribution focuses on teaching both the common and the distinguishing aspects of the two model categories\n",
        "\n",
        "**Underfitting vs. overfitting the model:** Underfitting means that your model makes accurate, but initially incorrect predictions. In this case, train error is large and val/test error is large too. Overfitting means that your model makes not accurate predictions. In this case, train error is very small and val/test error is large.\n",
        "\n",
        "**Bootstrapping vs. cross-validation:** Cross validation splits the available dataset to create multiple datasets, and Bootstrapping method uses the original dataset to create multiple datasets after resampling with replacement. Bootstrapping it is not as strong as Cross validation when it is used for model validation. Bootstrapping is more about building ensemble models or just estimating parameters."
      ],
      "metadata": {
        "id": "OGdbf3eWkJud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. Make quick notes on:**\n",
        "\n",
        "**LOOCV:** The Leave-One-Out Cross-Validation, or LOOCV, procedure is used to estimate the performance of machine learning algorithms when they are used to make predictions on data not used to train the model.\n",
        "\n",
        "It is a computationally expensive procedure to perform, although it results in a reliable and unbiased estimate of model performance. Although simple to use and no configuration to specify, there are times when the procedure should not be used, such as when you have a very large dataset or a computationally expensive model to evaluate.\n",
        "\n",
        "**F-measurement:** The F-score (also known as the F1 score or F-measure) is a metric used to evaluate the performance of a Machine Learning model. It combines precision and recall into a single score.\n",
        "\n",
        "**F-measure formula:--**  _**F-score = 2 * (precision * recall) / (precision + recall)**_\n",
        "\n",
        "\n",
        "\n",
        "**The width of the silhouette:** Silhouette coefficient ranges between âˆ’1 and 1, where a higher silhouette coefficient refers to a model with more coherent clusters. In other words, silhouette coefficients close to +1 means the sample is far away from the neighboring clusters\n",
        "\n",
        "**Receiver operating characteristic curve:** An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters: True Positive Rate. False Positive Rate"
      ],
      "metadata": {
        "id": "sjHadn_ukHa-"
      }
    }
  ]
}